{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYBKL+oAgvyJvm4FmNGM+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrismartel/COMP424/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Download Vehicle Dataset"
      ],
      "metadata": {
        "id": "QnE4ItFOypEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O output https://mcgill-my.sharepoint.com/:u:/g/personal/raghav_mehta_mail_mcgill_ca/EVEvhY9_jyVEk2uSZ8wZhFYBQ58C57I7ZB55jBocKwB5Jg?download=1\n",
        "!mv output dataset.zip\n",
        "!unzip dataset.zip\n",
        "!rm dataset.zip"
      ],
      "metadata": {
        "id": "evGmtRtpx1SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import cv2 as cv\n",
        "\n",
        "def parse(filepath):\n",
        "  '''\n",
        "      Parse gt.txt with format\n",
        "        <frame>, <id>, <type>, <truncated>, <occluded>, <alpha>, <bb_left>, <bb_top>, <bb_right>, <bb_bottom>, <3D_H>, <3D_W>, <3D_L>, <x>, <y>, <z>, <ry>\n",
        "      Return dict as:\n",
        "        <type> = \"Car\", \"Van\", \"Truck\", \"Pedastrian\", \"Person_sitting\", \"Cyclist\", \"Tram\", \"Misc\", \"DontCare\"\n",
        "        key: frame\n",
        "        value: list - <id>, <bb_left>, <bb_top>, <bb_right>, <bb_bottom>, <is_vehicle>\n",
        "      Feel free to edit your structure as needed!\n",
        "  '''\n",
        "\n",
        "  used_type = [\"Car\", \"Van\", \"Truck\", \"Tram\"]\n",
        "\n",
        "  lines = open(filepath, \"r\").readlines()                                 \n",
        "  bbox = {}\n",
        "\n",
        "       #  <frame>, <id>, <truncated>, <occluded>, <alpha>, <bb_left>, <bb_top>, <bb_right>, <bb_bottom>, <3D_H>, <3D_W>, <3D_L>, <x>,   <y>,   <z>,   <ry>\n",
        "  mask = [False,   True,  False,       False,      False,   True,      True,     True,       True,        False,  False,  False,  False, False, False, False]\n",
        "  \n",
        "  for line in lines:\n",
        "    l = line.strip().split(' ') #convert line to list\n",
        "    typ = l.pop(2)  # get type of bbox \n",
        "    line = np.asarray(l).astype(np.float32) # convert into array \n",
        "    frame, line = int(line[0]), line[mask] # get frame number and mask the line   \n",
        "    if frame not in bbox.keys():\n",
        "      bbox[frame] = []   \n",
        "    if typ in used_type:\n",
        "        bbox[frame].append(line)\n",
        "  return bbox\n",
        "\n",
        "def add_bbox(img, bbox, color=(255, 0, 0), thickness=2):\n",
        "  ''' \n",
        "    annotate an image with bounding boxes:\n",
        "    supports single bbox or list of bboxs\n",
        "  '''\n",
        "\n",
        "  annotated = np.copy(img)\n",
        "  if bbox: \n",
        "    if isinstance(bbox[0], np.ndarray) or isinstance(bbox[0], list):\n",
        "        for (_,x1,y1,x2,y2) in bbox:\n",
        "            cv.rectangle(annotated, (x1, y1), (x2, y2), color , thickness)\n",
        "    else:\n",
        "        _,x1,y1,x2,y2 = bbox\n",
        "        cv.rectangle(annotated, (x1, y1), (x2, y2), color , thickness)\n",
        "  \n",
        "  return annotated"
      ],
      "metadata": {
        "id": "mz9hXuewy1N7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "r1: tuple (x1,y1,x2,y2) coordinates of rectangle 1\n",
        "r2: tuple (x1,y1,x2,y2) coordinates of rectangle 2\n",
        "\"\"\"\n",
        "def intersection(r1, r2):\n",
        "  if r1[0] >= r2[2] or r1[2] <= r2[0] or r1[1] >= r2[3] or r1[3] <= r2[1]:\n",
        "    return False\n",
        "  else:\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "SRowSE1vJEdz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Dataset**\n",
        "\n",
        "https://iq.opengenus.org/object-detection-with-histogram-of-oriented-gradients-hog/"
      ],
      "metadata": {
        "id": "77efUfVlxzjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Positive Dataset\n",
        "\n",
        "Use provided bounding boxes from train dataset\n",
        "\n",
        "###Negative Dataset\n",
        "\n",
        "Use different objects from random patches in train dataset"
      ],
      "metadata": {
        "id": "4nyPjabFx3_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.cbook import maxdict\n",
        "import os\n",
        "import cv2 as cv\n",
        "from random import randint\n",
        "\n",
        "positive_dataset = list()\n",
        "\n",
        "negative_dataset = list()\n",
        "\n",
        "number_of_negative_samples_per_frame = 10\n",
        "\n",
        "minimum_bbox_h, maximum_bbox_h = 40, 150\n",
        "minimum_bbox_w, maximum_bbox_w = 50, 200\n",
        "\n",
        "max_diff_width_height = 20\n",
        "\n",
        "for image_sequence in range(4):\n",
        "  bboxes = parse('dataset/000{image_sequence}.txt'.format(image_sequence=image_sequence))\n",
        "  for frame_id, frame_bboxes in bboxes.items():\n",
        "\n",
        "    img = cv.imread('dataset/000{image_sequence}/{frame_id:06d}.png'.format(image_sequence=image_sequence, frame_id=frame_id))\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    for sample in range(number_of_negative_samples_per_frame):\n",
        "\n",
        "        while(True):\n",
        "          random_y1 = randint(0,img.shape[0])\n",
        "          random_y2 = randint(random_y1,img.shape[0])\n",
        "\n",
        "          random_x1 = randint(0,img.shape[1])\n",
        "          random_x2 = randint(random_x1,img.shape[1])\n",
        "\n",
        "          # validate dimensions\n",
        "          if random_y2 - random_y1 < minimum_bbox_h or random_y2 - random_y1 > maximum_bbox_h:\n",
        "            continue\n",
        "          if random_x2 - random_x1 < minimum_bbox_h or random_x2 - random_x1 > maximum_bbox_w:\n",
        "            continue\n",
        "\n",
        "          if abs((random_x2 - random_x1) - (random_y2 - random_y1)) > max_diff_width_height:\n",
        "            continue\n",
        "\n",
        "          random_bbox = (random_x1, random_y1, random_x2, random_y2)\n",
        "\n",
        "          # validate no-intersection with vehicles\n",
        "          valid = True\n",
        "          for (id, x1,y1,x2,y2) in frame_bboxes:\n",
        "            if intersection((x1,y1,x2,y2), random_bbox):\n",
        "              valid = False\n",
        "              break\n",
        "\n",
        "          if valid:\n",
        "            break\n",
        "\n",
        "        # extract patch\n",
        "        random_bbox_img = img[random_y1:random_y2,random_x1:random_x2]\n",
        "        negative_dataset.append(random_bbox_img)\n",
        "\n",
        "    for bbox in frame_bboxes:\n",
        "      id, x1, y1, x2, y2 = bbox.astype('int32')\n",
        "      \n",
        "      bbox_img = img[y1:y2,x1:x2]\n",
        "      positive_dataset.append(bbox_img)"
      ],
      "metadata": {
        "id": "L_ZIB2HQz0_J"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Class Distribution\n",
        "\n",
        "Display number of vehicle and non-vehicle images in dataset"
      ],
      "metadata": {
        "id": "c3fiVmsUTTV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.bar(['Vehicles','Non-Vehicles'],[len(positive_dataset),len(negative_dataset)], width=0.3)\n",
        "plt.ylabel('Quantity')\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "7QA0drCaSp67",
        "outputId": "47f589d3-1b00-4ad2-9e99-7c1de0f00e67"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Dataset Statistics\n",
        "\n",
        "- Aspect Ratio\n",
        "- Image Sizes"
      ],
      "metadata": {
        "id": "8Maer1thVU-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspect_ratios = np.zeros((len(positive_dataset)+len(negative_dataset)))\n",
        "min_aspect_ratio, max_aspect_ratio = np.iinfo(np.int32).max, 0\n",
        "\n",
        "widths = np.zeros((len(positive_dataset)+len(negative_dataset)))\n",
        "min_width, max_width = np.iinfo(np.int32).max, 0\n",
        "\n",
        "heights = np.zeros((len(positive_dataset)+len(negative_dataset)))\n",
        "min_height, max_height = np.iinfo(np.int32).max, 0\n",
        "\n",
        "for i, img in enumerate(positive_dataset + negative_dataset):\n",
        "  widths[i] = img.shape[1]\n",
        "  min_width = widths[i] if widths[i] < min_width else min_width\n",
        "  max_width = widths[i] if widths[i] > max_width else max_width\n",
        "\n",
        "  heights[i] = img.shape[0]\n",
        "  min_height = heights[i] if heights[i] < min_height else min_height\n",
        "  max_height = widths[i] if widths[i] > max_height else max_height\n",
        "\n",
        "  aspect_ratios[i] = heights[i] / widths[i]\n",
        "  min_aspect_ratio = aspect_ratios[i] if aspect_ratios[i] < min_aspect_ratio else min_aspect_ratio\n",
        "  max_aspect_ratio = aspect_ratios[i] if aspect_ratios[i] > max_aspect_ratio else max_aspect_ratio\n",
        "\n",
        "aspect_ratio_interval = int(max_aspect_ratio - min_aspect_ratio)\n",
        "width_interval = int(max_width - min_width)\n",
        "height_interval = int(max_height - min_height)\n",
        "\n",
        "aspect_ratio_banks = range(int(min_aspect_ratio), int(max_aspect_ratio), aspect_ratio_interval)\n",
        "width_banks = range(int(min_width), int(max_width), width_interval)\n",
        "height_banks = range(int(min_height), int(max_height), height_interval)"
      ],
      "metadata": {
        "id": "sJ4SYUe7T9J5"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_hdXep1davIU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}